{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from newsapi import NewsApiClient\n",
    "from dateutil.parser import parse\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NewsApi Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = NewsApiClient(api_key='XXXXXXXXXXXXXXXXXXXXXXXXXXXX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching News from get_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_Headline = api.get_everything(q='infosys',from_param='2020-02-25',to ='2020-03-03',language='en',page_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Articles = top_Headline['articles']  # Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Vader Lexicon to Financial Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refered Jason Yip TradeAlgo for Vader Financial Lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    " # stock market lexicon\n",
    "stock_lex = pd.read_csv('lexicon_data/stock_lex.csv')\n",
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4\n",
    "\n",
    " # Loughran and McDonald\n",
    "    positive = []\n",
    "    with open('lexicon_data/lm_positive.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            positive.append(row[0].strip())\n",
    "    \n",
    "    negative = []\n",
    "    with open('lexicon_data/lm_negative.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            entry = row[0].strip().split(\" \")\n",
    "            if len(entry) > 1:\n",
    "                negative.extend(entry)\n",
    "            else:\n",
    "                negative.append(entry[0])\n",
    "\n",
    "final_lex = {}\n",
    "final_lex.update({word:2.0 for word in positive})\n",
    "final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sia.lexicon)\n",
    "sia.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_sentiment(news): \n",
    "    # create Vader object of passed news text \n",
    "    sia = SentimentIntensityAnalyzer() \n",
    "    # set sentiment \n",
    "    if sia.polarity_scores(news)['compound'] >= 0.05 : \n",
    "        return 'Positive'  \n",
    "    elif sia.polarity_scores(news)['compound'] <= - 0.05 : \n",
    "        return 'Negative' \n",
    "    else : \n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for date in dates:\n",
    "    li = []\n",
    "    for article in Articles:\n",
    "        if (parse(article.get('publishedAt')).strftime('%Y-%m-%d') == str(date.date())) and (article.get('source').get('name') in ['Moneycontrol.com','Indianexpress.com','The Times of India','Business-standard.com']):\n",
    "            li.append(get_news_sentiment(article['description']))\n",
    "    \n",
    "    data[date.date().strftime('%Y-%m-%d')]=Counter(li).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
